{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "babc4c8d-f1de-40b3-b44c-55088d77e942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb5e85c-a274-4e4d-892f-a75fa0bf9be6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nENVIRONMENT SETUP\n======================================================================\nCurrent Catalog: hive_metastore\nCurrent Database: default\nSpark version: 4.0.0\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE CATALOG hive_metastore\")\n",
    "spark.sql(\"USE default\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT SETUP\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Current Catalog: {spark.sql('SELECT current_catalog()').collect()[0][0]}\")\n",
    "print(f\"Current Database: {spark.sql('SELECT current_database()').collect()[0][0]}\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2db3f9a-4c2c-4f28-9a4f-474b6a294560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nML MODEL REGISTRY\n======================================================================\n\nExperiment ID: 2575000388711542\nExperiment Name: /Users/hingushrey2707@gmail.com/nyc-taxi-prediction\n\nSearching for best model in MLFlow...\n\nBest Run Found (from MLFlow):\n  Run ID: 9254956582fb4d19bec2029d0e6f6fb4\n  Model: 03_gbt_v1\n  RMSE: 4.79 minutes\n  MAE: 2.22 minutes\n  R²: 0.8776\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Find Best Model from MLFlow\n",
    "# ============================================\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ML MODEL REGISTRY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get experiment\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_name = f\"/Users/{username}/nyc-taxi-prediction\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    raise Exception(f\"Experiment '{experiment_name}' not found! Run Notebook 04 first.\")\n",
    "\n",
    "print(f\"\\nExperiment ID: {experiment.experiment_id}\")\n",
    "print(f\"Experiment Name: {experiment_name}\")\n",
    "\n",
    "# Method 1: Try to get best model from MLFlow runs (primary method)\n",
    "print(\"\\nSearching for best model in MLFlow...\")\n",
    "\n",
    "try:\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string=\"metrics.rmse > 0\",\n",
    "        order_by=[\"metrics.rmse ASC\"],\n",
    "        max_results=1\n",
    "    )\n",
    "    \n",
    "    if len(runs) == 0:\n",
    "        raise Exception(\"No runs with logged metrics found\")\n",
    "    \n",
    "    best_run = runs.iloc[0]\n",
    "    best_run_id = best_run[\"run_id\"]\n",
    "    \n",
    "    # Get model metadata\n",
    "    best_model_name = best_run['tags.mlflow.runName']\n",
    "    best_rmse = best_run['metrics.rmse']\n",
    "    best_mae = best_run['metrics.mae']\n",
    "    best_r2 = best_run['metrics.r2']\n",
    "    \n",
    "    print(f\"\\nBest Run Found (from MLFlow):\")\n",
    "    print(f\"  Run ID: {best_run_id}\")\n",
    "    print(f\"  Model: {best_model_name}\")\n",
    "    print(f\"  RMSE: {best_rmse:.2f} minutes\")\n",
    "    print(f\"  MAE: {best_mae:.2f} minutes\")\n",
    "    print(f\"  R²: {best_r2:.4f}\")\n",
    "    \n",
    "    mlflow_method_success = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not find metrics in MLFlow: {str(e)}\")\n",
    "    mlflow_method_success = False\n",
    "\n",
    "# Method 2: Fallback to model_comparison_metrics table (backup method)\n",
    "if not mlflow_method_success:\n",
    "    print(\"\\nTrying backup method: model_comparison_metrics table...\")\n",
    "    \n",
    "    try:\n",
    "        # Load from the table you created in Notebook 04\n",
    "        model_metrics_df = spark.table(\"model_comparison_metrics\").orderBy(\"rmse\")\n",
    "        best_model_row = model_metrics_df.first()\n",
    "        \n",
    "        if best_model_row is None:\n",
    "            raise Exception(\"No models found in comparison table!\")\n",
    "        \n",
    "        best_model_name = best_model_row[\"model_name\"]\n",
    "        best_rmse = best_model_row[\"rmse\"]\n",
    "        best_mae = best_model_row[\"mae\"]\n",
    "        best_r2 = best_model_row[\"r2\"]\n",
    "        \n",
    "        # Find the run_id for this model\n",
    "        runs_all = mlflow.search_runs(\n",
    "            experiment_ids=[experiment.experiment_id],\n",
    "            filter_string=f\"tags.mlflow.runName LIKE '%{best_model_name}%'\"\n",
    "        )\n",
    "        \n",
    "        if len(runs_all) > 0:\n",
    "            best_run_id = runs_all.iloc[0][\"run_id\"]\n",
    "        else:\n",
    "            raise Exception(f\"Could not find MLFlow run for {best_model_name}\")\n",
    "        \n",
    "        print(f\"\\nBest Model Found (from comparison table):\")\n",
    "        print(f\"  Run ID: {best_run_id}\")\n",
    "        print(f\"  Model: {best_model_name}\")\n",
    "        print(f\"  RMSE: {best_rmse:.2f} minutes\")\n",
    "        print(f\"  MAE: {best_mae:.2f} minutes\")\n",
    "        print(f\"  R²: {best_r2:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nFATAL ERROR: Could not find best model anywhere!\")\n",
    "        print(f\"   Error: {str(e)}\")\n",
    "        print(f\"\\nPlease ensure you have:\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "463d8700-b036-4797-a9c8-cc9f9ae9b580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nMLFLOW REGISTRY CONFIGURATION\n======================================================================\nConfigured to use Legacy Workspace Model Registry\n   Registry URI: databricks\n   Model naming: Simple format (no catalog/schema required)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Configure Legacy Workspace Registry\n",
    "# ============================================\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Switch to legacy Workspace Model Registry\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MLFLOW REGISTRY CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Configured to use Legacy Workspace Model Registry\")\n",
    "print(f\"   Registry URI: {mlflow.get_registry_uri()}\")\n",
    "print(f\"   Model naming: Simple format (no catalog/schema required)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543cafde-452c-48eb-9195-2a09f9a47b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nLOADING MODEL FROM DBFS\n======================================================================\n\nLoading model from DBFS...\n   Path: /mnt/taxi-data/models/best_gradient_boosted_trees\n   Model Type: gbt\nModel loaded successfully from DBFS\n\nModel Performance:\n   RMSE: 4.79 minutes\n   MAE: 2.22 minutes\n   R²: 0.8776\n\nCreating new MLFlow run with model artifact...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/03 03:27:55 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f07d22cf4a4422595318fae3e49c06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/03 03:28:46 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/2386689747319461/c8b3d838d0f64e89b9821cd76225b22b/artifacts/model/sparkml, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d155e67b9b24e54bade59709efafab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nNew run created with model artifact!\n   New Run ID: c8b3d838d0f64e89b9821cd76225b22b\n   Original Run ID: 9254956582fb4d19bec2029d0e6f6fb4\n\n======================================================================\nREGISTERING MODEL TO MLFLOW REGISTRY\n======================================================================\n\nModel Details:\n  Registry Name: nyc_taxi_duration_predictor\n  Model Type: Gbt\n  Source Path: /mnt/taxi-data/models/best_gradient_boosted_trees\n  Performance: RMSE=4.79, MAE=2.22, R²=0.8776\n\nFound 2 existing version(s) in registry\n\nRegistering model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'nyc_taxi_duration_predictor' already exists. Creating a new version of this model...\n2025/12/03 03:28:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: nyc_taxi_duration_predictor, version 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nModel registered successfully!\n   Model Name: nyc_taxi_duration_predictor\n   Version: 3\n   Status: PENDING_REGISTRATION\n   Source Model: 03_gbt_v1\n\n======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'nyc_taxi_duration_predictor'.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Load Model from DBFS and Register\n",
    "# ============================================\n",
    "\n",
    "import re\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING MODEL FROM DBFS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Clean up model name for registry\n",
    "clean_model_name = re.sub(r'^\\d+_', '', best_model_name)\n",
    "clean_model_name = re.sub(r'_v\\d+$', '', clean_model_name)\n",
    "\n",
    "# Determine model path based on best model name\n",
    "# Map run names to saved model paths\n",
    "model_path_mapping = {\n",
    "    \"linear_regression\": \"/mnt/taxi-data/models/best_linear_regression\",\n",
    "    \"random_forest\": \"/mnt/taxi-data/models/best_random_forest\",\n",
    "    \"gbt\": \"/mnt/taxi-data/models/best_gradient_boosted_trees\",\n",
    "    \"gradient_boosted_trees\": \"/mnt/taxi-data/models/best_gradient_boosted_trees\"\n",
    "}\n",
    "\n",
    "# Find the model path\n",
    "model_path = None\n",
    "for key, path in model_path_mapping.items():\n",
    "    if key in clean_model_name.lower():\n",
    "        model_path = path\n",
    "        break\n",
    "\n",
    "if model_path is None:\n",
    "    # Default to gradient boosted trees (best performing)\n",
    "    model_path = \"/mnt/taxi-data/models/best_gradient_boosted_trees\"\n",
    "    print(f\"\\nCould not map model name, using default: {model_path}\")\n",
    "\n",
    "print(f\"\\nLoading model from DBFS...\")\n",
    "print(f\"   Path: {model_path}\")\n",
    "print(f\"   Model Type: {clean_model_name}\")\n",
    "\n",
    "# Load the appropriate model type\n",
    "try:\n",
    "    if \"linear\" in clean_model_name.lower():\n",
    "        from pyspark.ml.regression import LinearRegressionModel\n",
    "        loaded_model = LinearRegressionModel.load(model_path)\n",
    "    elif \"random_forest\" in clean_model_name.lower() or \"rf\" in clean_model_name.lower():\n",
    "        from pyspark.ml.regression import RandomForestRegressionModel\n",
    "        loaded_model = RandomForestRegressionModel.load(model_path)\n",
    "    else:  # GBT\n",
    "        from pyspark.ml.regression import GBTRegressionModel\n",
    "        loaded_model = GBTRegressionModel.load(model_path)\n",
    "    \n",
    "    print(f\"Model loaded successfully from DBFS\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to load model from {model_path}\")\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Get metrics (either from MLFlow or from comparison table)\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"   RMSE: {best_rmse:.2f} minutes\")\n",
    "print(f\"   MAE: {best_mae:.2f} minutes\")\n",
    "print(f\"   R²: {best_r2:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# Create New MLFlow Run and Log Model\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\nCreating new MLFlow run with model artifact...\")\n",
    "\n",
    "# Create new run and log the model\n",
    "with mlflow.start_run(run_name=f\"{clean_model_name}_for_registry\") as new_run:\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", best_rmse)\n",
    "    mlflow.log_metric(\"mae\", best_mae)\n",
    "    mlflow.log_metric(\"r2\", best_r2)\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", clean_model_name.replace('_', ' ').title())\n",
    "    mlflow.log_param(\"source\", \"loaded_from_dbfs\")\n",
    "    mlflow.log_param(\"original_run_id\", best_run_id)\n",
    "    \n",
    "    # Log the model artifact\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=loaded_model,\n",
    "        artifact_path=\"model\"\n",
    "    )\n",
    "    \n",
    "    new_run_id = new_run.info.run_id\n",
    "    \n",
    "    print(f\"\\nNew run created with model artifact!\")\n",
    "    print(f\"   New Run ID: {new_run_id}\")\n",
    "    print(f\"   Original Run ID: {best_run_id}\")\n",
    "\n",
    "# ============================================\n",
    "# Register Model to Registry\n",
    "# ============================================\n",
    "\n",
    "registry_model_name = \"nyc_taxi_duration_predictor\"\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"REGISTERING MODEL TO MLFLOW REGISTRY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nModel Details:\")\n",
    "print(f\"  Registry Name: {registry_model_name}\")\n",
    "print(f\"  Model Type: {clean_model_name.replace('_', ' ').title()}\")\n",
    "print(f\"  Source Path: {model_path}\")\n",
    "print(f\"  Performance: RMSE={best_rmse:.2f}, MAE={best_mae:.2f}, R²={best_r2:.4f}\")\n",
    "\n",
    "# Check existing versions\n",
    "try:\n",
    "    existing_versions = client.search_model_versions(f\"name='{registry_model_name}'\")\n",
    "    print(f\"\\nFound {len(existing_versions)} existing version(s) in registry\")\n",
    "except:\n",
    "    print(f\"\\nNo existing versions found (first registration)\")\n",
    "\n",
    "# Register the model\n",
    "print(f\"\\nRegistering model...\")\n",
    "\n",
    "try:\n",
    "    model_details = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{new_run_id}/model\",\n",
    "        name=registry_model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel registered successfully!\")\n",
    "    print(f\"   Model Name: {registry_model_name}\")\n",
    "    print(f\"   Version: {model_details.version}\")\n",
    "    print(f\"   Status: {model_details.status}\")\n",
    "    print(f\"   Source Model: {best_model_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nRegistration failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330eecb8-6a57-4a74-8d72-1562233d1359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nMODEL LIFECYCLE MANAGEMENT\n======================================================================\n\nModel description updated\n\nTransitioning model through lifecycle stages...\n\n[1/2] Transitioning to Staging...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1596/command-4562284824223434-1787018744:74: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n  client.transition_model_version_stage(\n/root/.ipykernel/1596/command-4562284824223434-1787018744:84: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n  client.transition_model_version_stage(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 3 → Staging\n\n[2/2] Transitioning to Production...\nVersion 3 → Production\n\n======================================================================\nMODEL LIFECYCLE STAGES:\n  None → Staging → Production\n======================================================================\n\nVersion 3 description updated\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Update Model Description and Lifecycle\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL LIFECYCLE MANAGEMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Create comprehensive model description\n",
    "description = f\"\"\"\n",
    "NYC Yellow Taxi Trip Duration Prediction Model\n",
    "\n",
    "MODEL INFORMATION:\n",
    "- Algorithm: {clean_model_name.replace('_', ' ').title()}\n",
    "- Training Framework: Apache Spark MLlib\n",
    "- Use Case: Trip duration prediction for dispatch planning\n",
    "\n",
    "PERFORMANCE METRICS:\n",
    "- RMSE: {best_rmse:.2f} minutes\n",
    "- MAE: {best_mae:.2f} minutes  \n",
    "- R² Score: {best_r2:.4f}\n",
    "- Best among: Linear Regression, Random Forest, Gradient Boosted Trees\n",
    "\n",
    "FEATURES (8 total):\n",
    "1. trip_distance - Distance in miles\n",
    "2. passenger_count - Number of passengers (1-6)\n",
    "3. fare_amount - Trip fare in USD\n",
    "4. hour_of_day - Hour of day (0-23)\n",
    "5. day_of_week - Day of week (1=Sunday, 7=Saturday)\n",
    "6. is_weekend - Weekend indicator (0/1)\n",
    "7. PULocationID - Pickup location zone (indexed)\n",
    "8. DOLocationID - Dropoff location zone (indexed)\n",
    "\n",
    "TRAINING DETAILS:\n",
    "- Dataset: NYC TLC Yellow Taxi (Jan 2024 - Jun 2025)\n",
    "- Training Samples: ~42.5M trips\n",
    "- Test Samples: ~10.6M trips\n",
    "- Data Size: 1.05 GB (53M+ total rows)\n",
    "- Distributed Training: Yes (Spark cluster with 2-4 workers)\n",
    "\n",
    "ARCHITECTURE:\n",
    "- Platform: Azure Databricks\n",
    "- Storage: Delta Lake (ACID compliant)\n",
    "- Partitioning: By year and month\n",
    "- ML Pipeline: VectorAssembler + StandardScaler + Model\n",
    "- Experiment Tracking: MLFlow\n",
    "\n",
    "METADATA:\n",
    "- Model Version: {model_details.version}\n",
    "- Source Run: {best_run_id}\n",
    "- Run Name: {best_model_name}\n",
    "- Registered: {model_details.creation_timestamp}\n",
    "\n",
    "DEPLOYMENT:\n",
    "Ready for production inference on batch and streaming data.\n",
    "\"\"\"\n",
    "\n",
    "# Update model description\n",
    "client.update_registered_model(\n",
    "    name=registry_model_name,\n",
    "    description=description\n",
    ")\n",
    "\n",
    "print(f\"\\nModel description updated\")\n",
    "\n",
    "# Lifecycle Stage Transitions\n",
    "print(f\"\\nTransitioning model through lifecycle stages...\")\n",
    "\n",
    "# Stage 1: Move to Staging\n",
    "print(f\"\\n[1/2] Transitioning to Staging...\")\n",
    "client.transition_model_version_stage(\n",
    "    name=registry_model_name,\n",
    "    version=model_details.version,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=False  # Keep old versions\n",
    ")\n",
    "print(f\"Version {model_details.version} → Staging\")\n",
    "\n",
    "# Stage 2: Move to Production  \n",
    "print(f\"\\n[2/2] Transitioning to Production...\")\n",
    "client.transition_model_version_stage(\n",
    "    name=registry_model_name,\n",
    "    version=model_details.version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True  # Archive old production versions\n",
    ")\n",
    "print(f\"Version {model_details.version} → Production\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL LIFECYCLE STAGES:\")\n",
    "print(\"  None → Staging → Production\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Add version description\n",
    "version_description = f\"\"\"\n",
    "Best performing model: {clean_model_name.replace('_', ' ').title()}\n",
    "RMSE: {best_rmse:.2f} min | MAE: {best_mae:.2f} min | R²: {best_r2:.4f}\n",
    "Promoted to Production based on lowest RMSE among all baseline models.\n",
    "\"\"\"\n",
    "\n",
    "client.update_model_version(\n",
    "    name=registry_model_name,\n",
    "    version=model_details.version,\n",
    "    description=version_description\n",
    ")\n",
    "\n",
    "print(f\"\\nVersion {model_details.version} description updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "975d0f3a-0350-4bb0-8943-42dedd4e771b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nPRODUCTION MODEL TESTING\n======================================================================\n\nLoading production model from registry...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9460c4b1307a48a7aea36cd0300dbad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production model loaded successfully!\n   Model: nyc_taxi_duration_predictor\n   Stage: Production\n   Version: 3\n\nTesting model with sample data...\n\nPredictions successful!\n\nSample Predictions (First 10 rows):\n======================================================================\n+------------------+------------------+-------------------+\n|Actual (min)      |Predicted (min)   |Error (min)        |\n+------------------+------------------+-------------------+\n|33.35             |34.10186822188318 |0.7518682218831785 |\n|9.15              |6.955730689199445 |2.1942693108005553 |\n|8.583333333333334 |7.414722298119862 |1.1686110352134715 |\n|2.8666666666666667|2.4456718750729975|0.42099479159366915|\n|8.316666666666666 |7.673308148864867 |0.6433585178017998 |\n|44.2              |37.95390848711456 |6.246091512885442  |\n|9.983333333333333 |10.249253729994667|0.2659203966613344 |\n|9.683333333333334 |9.259646573300543 |0.4236867600327905 |\n|13.2              |13.063136089601484|0.13686391039851564|\n|10.3              |9.793411708832465 |0.5065882911675352 |\n+------------------+------------------+-------------------+\n\n\nSample Statistics:\n  Average Actual Duration: 18.32 minutes\n  Average Predicted Duration: 16.65 minutes\n  Average Absolute Error: 2.12 minutes\n\n======================================================================\nPRODUCTION MODEL READY FOR DEPLOYMENT\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Load and Test Production Model\n",
    "# ============================================\n",
    "\n",
    "from pyspark.sql.functions import avg, abs as spark_abs, col\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRODUCTION MODEL TESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nLoading production model from registry...\")\n",
    "\n",
    "production_model_uri = f\"models:/{registry_model_name}/Production\"\n",
    "\n",
    "try:\n",
    "    production_model = mlflow.spark.load_model(production_model_uri)\n",
    "    print(f\"Production model loaded successfully!\")\n",
    "    print(f\"   Model: {registry_model_name}\")\n",
    "    print(f\"   Stage: Production\")\n",
    "    print(f\"   Version: {model_details.version}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load production model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Test prediction on sample data\n",
    "print(f\"\\nTesting model with sample data...\")\n",
    "\n",
    "try:\n",
    "    test_sample = spark.table(\"taxi_ml_test\").limit(10)\n",
    "    test_predictions = production_model.transform(test_sample)\n",
    "    \n",
    "    print(f\"\\nPredictions successful!\")\n",
    "    print(f\"\\nSample Predictions (First 10 rows):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_predictions.select(\n",
    "        col(\"trip_duration_minutes\").alias(\"Actual (min)\"),\n",
    "        col(\"prediction\").alias(\"Predicted (min)\"),\n",
    "        spark_abs(col(\"prediction\") - col(\"trip_duration_minutes\")).alias(\"Error (min)\")\n",
    "    ).show(10, truncate=False)\n",
    "    \n",
    "    # Calculate sample accuracy\n",
    "    sample_metrics = test_predictions.select(\n",
    "        avg(spark_abs(col(\"prediction\") - col(\"trip_duration_minutes\"))).alias(\"avg_error\"),\n",
    "        avg(col(\"trip_duration_minutes\")).alias(\"avg_actual\"),\n",
    "        avg(col(\"prediction\")).alias(\"avg_predicted\")\n",
    "    ).first()\n",
    "    \n",
    "    print(f\"\\nSample Statistics:\")\n",
    "    print(f\"  Average Actual Duration: {sample_metrics['avg_actual']:.2f} minutes\")\n",
    "    print(f\"  Average Predicted Duration: {sample_metrics['avg_predicted']:.2f} minutes\")\n",
    "    print(f\"  Average Absolute Error: {sample_metrics['avg_error']:.2f} minutes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Prediction test failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRODUCTION MODEL READY FOR DEPLOYMENT\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163ed05a-aa2c-48ee-8be6-071ca1427e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPreparing new data for batch inference...\nNew trips to process: 3,185,044\n✓ Data preprocessed and ready for inference\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Prepare New Data for Inference\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nPreparing new data for batch inference...\")\n",
    "\n",
    "# Simulate \"new\" data using a specific month as unseen data\n",
    "# Using most recent month in your dataset\n",
    "new_trips = spark.table(\"taxi_trips\").filter(\n",
    "    (col(\"year\") == 2024) & (col(\"month\") == 12)\n",
    ")\n",
    "\n",
    "print(f\"New trips to process: {new_trips.count():,}\")\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "preprocessing = PipelineModel.load(\"/mnt/taxi-data/models/preprocessing_pipeline\")\n",
    "\n",
    "# Apply preprocessing\n",
    "new_data_processed = preprocessing.transform(new_trips)\n",
    "new_data_ml = new_data_processed.select(\n",
    "    \"features\",\n",
    "    \"trip_duration_minutes\",\n",
    "    \"trip_distance\",\n",
    "    \"hour_of_day\",\n",
    "    \"day_of_week\"\n",
    ")\n",
    "\n",
    "print(\"✓ Data preprocessed and ready for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b141caa-a120-40ff-a525-50900424e646",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nRunning batch predictions...\nDS FEATURE: Distributed inference across cluster\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e27268a44c4f98a7f9cdd98291f474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n======================================================================\nBATCH INFERENCE PERFORMANCE\n======================================================================\nTotal Predictions: 3,185,044\nInference Time: 10.25 seconds\nThroughput: 310730 predictions/second\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Run Batch Predictions\n",
    "# DS FEATURE: Distributed batch processing\n",
    "# ============================================\n",
    "\n",
    "import time \n",
    "\n",
    "print(\"\\nRunning batch predictions...\")\n",
    "print(\"DS FEATURE: Distributed inference across cluster\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions\n",
    "prod_model = mlflow.spark.load_model(production_model_uri)\n",
    "predictions = prod_model.transform(new_data_ml)\n",
    "\n",
    "# Force evaluation and count\n",
    "pred_count = predictions.count()\n",
    "\n",
    "inference_time = time.time() - start_time\n",
    "throughput = pred_count / inference_time if inference_time > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BATCH INFERENCE PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Predictions: {pred_count:,}\")\n",
    "print(f\"Inference Time: {inference_time:.2f} seconds\")\n",
    "print(f\"Throughput: {throughput:.0f} predictions/second\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d00904-5f6b-40e0-b8ff-4f468e211539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEnriching predictions with business metrics...\nPredictions enriched with error metrics and categories\n\nSample Enriched Predictions:\n+-----------------------+--------------------------+-------------------+------------------+-----------------+\n|actual_duration_minutes|predicted_duration_minutes|      error_minutes|  error_percentage|accuracy_category|\n+-----------------------+--------------------------+-------------------+------------------+-----------------+\n|     36.583333333333336|         41.89129394341718|  5.307960610083846|14.509231735992289|             Fair|\n|      8.483333333333333|         8.955167405314453|0.47183407198112093| 5.561894758127163|        Excellent|\n|     26.116666666666667|        24.886576815853495| 1.2300898508131723| 4.709980283904935|        Excellent|\n|     13.916666666666666|         14.49185406043568| 0.5751873937690135|   4.1330830689989|        Excellent|\n|                    9.4|         9.802226407944177|0.40222640794417686| 4.279004339831668|        Excellent|\n|                  14.35|         16.10452458166399| 1.7545245816639916|  12.2266521370313|        Excellent|\n|     20.916666666666668|         19.74977228042394| 1.1668943862427277| 5.578777942196307|        Excellent|\n|     20.516666666666666|        23.186885249618076|   2.67021858295141|13.014875302768855|             Good|\n|                   23.5|         19.74977228042394|   3.75022771957606|15.958415827983233|             Good|\n|                   7.15|         6.972481912435945|0.17751808756405563| 2.482770455441337|        Excellent|\n+-----------------------+--------------------------+-------------------+------------------+-----------------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Enrich Predictions with Business Logic\n",
    "# ============================================\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "print(\"\\nEnriching predictions with business metrics...\")\n",
    "\n",
    "predictions_enriched = predictions.withColumn(\n",
    "    \"predicted_duration_minutes\",\n",
    "    col(\"prediction\")\n",
    ").withColumn(\n",
    "    \"actual_duration_minutes\",\n",
    "    col(\"trip_duration_minutes\")\n",
    ").withColumn(\n",
    "    \"error_minutes\",\n",
    "    abs(col(\"prediction\") - col(\"trip_duration_minutes\"))\n",
    ").withColumn(\n",
    "    \"error_percentage\",\n",
    "    (abs(col(\"prediction\") - col(\"trip_duration_minutes\")) / col(\"trip_duration_minutes\")) * 100\n",
    ").withColumn(\n",
    "    \"accuracy_category\",\n",
    "    when(col(\"error_minutes\") < 2, \"Excellent\")\n",
    "    .when(col(\"error_minutes\") < 5, \"Good\")\n",
    "    .when(col(\"error_minutes\") < 10, \"Fair\")\n",
    "    .otherwise(\"Poor\")\n",
    ").withColumn(\n",
    "    \"prediction_timestamp\",\n",
    "    current_timestamp()\n",
    ")\n",
    "\n",
    "print(\"Predictions enriched with error metrics and categories\")\n",
    "\n",
    "# Show sample enriched predictions\n",
    "print(\"\\nSample Enriched Predictions:\")\n",
    "predictions_enriched.select(\n",
    "    \"actual_duration_minutes\",\n",
    "    \"predicted_duration_minutes\",\n",
    "    \"error_minutes\",\n",
    "    \"error_percentage\",\n",
    "    \"accuracy_category\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ae4b4a-80c4-4c02-863f-c29ee5f08f96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nSaving predictions to Delta Lake...\nPredictions saved to: /mnt/taxi-data/delta/predictions\nTable created: taxi_predictions\nPartitioned by: accuracy_category\nFormat: Delta Lake (ACID-compliant)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Save Predictions to Delta Lake\n",
    "# DS FEATURE: ACID transactions\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nSaving predictions to Delta Lake...\")\n",
    "\n",
    "predictions_path = \"/mnt/taxi-data/delta/predictions\"\n",
    "\n",
    "predictions_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"accuracy_category\") \\\n",
    "    .save(predictions_path)\n",
    "\n",
    "# Register as table\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS taxi_predictions\n",
    "    USING DELTA\n",
    "    LOCATION '{predictions_path}'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Predictions saved to: {predictions_path}\")\n",
    "print(\"Table created: taxi_predictions\")\n",
    "print(\"Partitioned by: accuracy_category\")\n",
    "print(\"Format: Delta Lake (ACID-compliant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "835e1c04-672d-4f5b-a05b-ea61f5c192a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n======================================================================\nPREDICTION QUALITY ANALYSIS\n======================================================================\n\nOverall Statistics:\n  Total Predictions: 3,185,044\n  Avg Error: 2.41 minutes\n  Std Dev: 4.73 minutes\n  Median Error: 1.01 minutes\n  95th Percentile: 9.65 minutes\n\nPredictions by Accuracy Category:\n+-----------------+-------+----------+---------+\n|accuracy_category|  count|percentage|avg_error|\n+-----------------+-------+----------+---------+\n|        Excellent|2313264|      72.6|     0.76|\n|             Good| 522448|      16.4|     3.06|\n|             Fair| 197543|       6.2|     6.98|\n|             Poor| 151789|       4.8|    19.43|\n+-----------------+-------+----------+---------+\n\n\nPrediction Accuracy by Hour of Day:\n+-----------+-----------+---------+\n|hour_of_day|predictions|avg_error|\n+-----------+-----------+---------+\n|          0|      89274|     2.18|\n|          1|      54184|     1.84|\n|          2|      32495|     1.67|\n|          3|      20318|     1.81|\n|          4|      14534|     2.75|\n|          5|      16138|     3.87|\n|          6|      35820|     3.52|\n|          7|      75905|     2.97|\n|          8|     108908|     2.55|\n|          9|     128960|     2.37|\n|         10|     147753|     2.44|\n|         11|     164371|     2.49|\n|         12|     179106|     2.52|\n|         13|     184272|     2.64|\n|         14|     199613|     2.87|\n|         15|     208896|     2.93|\n|         16|     208639|     2.99|\n|         17|     217273|     2.51|\n|         18|     225337|     2.11|\n|         19|     200615|     1.98|\n|         20|     185956|     1.97|\n|         21|     188562|     1.91|\n|         22|     167816|     1.96|\n|         23|     130299|     2.15|\n+-----------+-----------+---------+\n\n\nPrediction Accuracy by Day of Week:\n+-----------+---------+-----------+---------+\n|day_of_week| day_name|predictions|avg_error|\n+-----------+---------+-----------+---------+\n|          1|   Sunday|     449931|     2.35|\n|          2|   Monday|     461905|      2.6|\n|          3|  Tuesday|     496917|     2.33|\n|          4|Wednesday|     411411|     2.52|\n|          5| Thursday|     460803|     2.62|\n|          6|   Friday|     458944|     2.38|\n|          7| Saturday|     445133|     2.11|\n+-----------+---------+-----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Prediction Quality Analysis\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTION QUALITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Overall statistics\n",
    "overall_stats = predictions_enriched.select(\n",
    "    count(\"*\").alias(\"total_predictions\"),\n",
    "    round(avg(\"error_minutes\"), 2).alias(\"avg_error_minutes\"),\n",
    "    round(stddev(\"error_minutes\"), 2).alias(\"stddev_error\"),\n",
    "    round(percentile_approx(\"error_minutes\", 0.5), 2).alias(\"median_error\"),\n",
    "    round(percentile_approx(\"error_minutes\", 0.95), 2).alias(\"p95_error\")\n",
    ").collect()[0]\n",
    "\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(f\"  Total Predictions: {overall_stats['total_predictions']:,}\")\n",
    "print(f\"  Avg Error: {overall_stats['avg_error_minutes']:.2f} minutes\")\n",
    "print(f\"  Std Dev: {overall_stats['stddev_error']:.2f} minutes\")\n",
    "print(f\"  Median Error: {overall_stats['median_error']:.2f} minutes\")\n",
    "print(f\"  95th Percentile: {overall_stats['p95_error']:.2f} minutes\")\n",
    "\n",
    "# By accuracy category\n",
    "print(\"\\nPredictions by Accuracy Category:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        accuracy_category,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage,\n",
    "        ROUND(AVG(error_minutes), 2) as avg_error\n",
    "    FROM taxi_predictions\n",
    "    GROUP BY accuracy_category\n",
    "    ORDER BY \n",
    "        CASE accuracy_category\n",
    "            WHEN 'Excellent' THEN 1\n",
    "            WHEN 'Good' THEN 2\n",
    "            WHEN 'Fair' THEN 3\n",
    "            ELSE 4\n",
    "        END\n",
    "\"\"\").show()\n",
    "\n",
    "# By hour of day\n",
    "print(\"\\nPrediction Accuracy by Hour of Day:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        hour_of_day,\n",
    "        COUNT(*) as predictions,\n",
    "        ROUND(AVG(error_minutes), 2) as avg_error\n",
    "    FROM taxi_predictions\n",
    "    GROUP BY hour_of_day\n",
    "    ORDER BY hour_of_day\n",
    "\"\"\").show(24)\n",
    "\n",
    "# By day of week\n",
    "print(\"\\nPrediction Accuracy by Day of Week:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        day_of_week,\n",
    "        CASE day_of_week\n",
    "            WHEN 1 THEN 'Sunday'\n",
    "            WHEN 2 THEN 'Monday'\n",
    "            WHEN 3 THEN 'Tuesday'\n",
    "            WHEN 4 THEN 'Wednesday'\n",
    "            WHEN 5 THEN 'Thursday'\n",
    "            WHEN 6 THEN 'Friday'\n",
    "            WHEN 7 THEN 'Saturday'\n",
    "        END as day_name,\n",
    "        COUNT(*) as predictions,\n",
    "        ROUND(AVG(error_minutes), 2) as avg_error\n",
    "    FROM taxi_predictions\n",
    "    GROUP BY day_of_week\n",
    "    ORDER BY day_of_week\n",
    "\"\"\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_Model_Registry_Production",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}