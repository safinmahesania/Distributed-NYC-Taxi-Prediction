{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b085f920-438a-4771-b964-277af0449f39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "389d8622-810c-41ef-baac-dc5ef0d964da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nENVIRONMENT SETUP\n======================================================================\n✓ Current Catalog: hive_metastore\n✓ Current Database: default\n✓ Spark version: 4.0.0\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE CATALOG hive_metastore\")\n",
    "spark.sql(\"USE default\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT SETUP\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✓ Current Catalog: {spark.sql('SELECT current_catalog()').collect()[0][0]}\")\n",
    "print(f\"✓ Current Database: {spark.sql('SELECT current_database()').collect()[0][0]}\")\n",
    "print(f\"✓ Spark version: {spark.version}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72f0b963-28db-41a6-923e-21a2701feade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/02 21:36:26 WARNING mlflow.utils.autologging_utils: MLflow spark autologging is known to be compatible with 3.2.1 <= pyspark <= 3.5.5, but the installed version is 4.0.0. If you encounter errors during autologging, try upgrading / downgrading pyspark to a compatible version, or try upgrading MLflow.\n2025/12/02 21:36:26 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\nMLFLOW EXPERIMENT SETUP\n======================================================================\nExperiment: /Users/hingushrey2707@gmail.com/nyc-taxi-prediction\nAutologging: ENABLED\nMLFlow version: 3.0.1\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Setup MLFlow\n",
    "# ============================================\n",
    "\n",
    "# Set experiment\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_name = f\"/Users/{username}/nyc-taxi-prediction\"\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.spark.autolog()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MLFLOW EXPERIMENT SETUP\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "print(f\"Autologging: ENABLED\")\n",
    "print(f\"MLFlow version: {mlflow.__version__}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e017d001-130a-4471-b8fd-1eaa314c0fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTraining data: 42,487,529 samples\nTest data: 10,619,390 samples\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Load ML Data\n",
    "# ============================================\n",
    "\n",
    "train = spark.table(\"taxi_ml_train\")\n",
    "test = spark.table(\"taxi_ml_test\")\n",
    "\n",
    "# Force evaluation and cache\n",
    "train.cache().count()\n",
    "test.cache().count()\n",
    "\n",
    "print(f\"\\nTraining data: {train.count():,} samples\")\n",
    "print(f\"Test data: {test.count():,} samples\")\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"trip_duration_minutes\",\n",
    "    predictionCol=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa806e62-9652-40c9-987e-d6f5391397b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n============================================================\nMODEL 1: LINEAR REGRESSION (BASELINE)\n============================================================\nMLFlow Run ID: 1440703963464261b8376c9d0792e991\n\nTraining time: 44.88 seconds\nRMSE: 7.30 minutes\nMAE: 4.22 minutes\nR²: 0.7151\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Model 1 - Linear Regression (Baseline)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 1: LINEAR REGRESSION (BASELINE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with mlflow.start_run(run_name=\"01_linear_regression_baseline\") as run:\n",
    "    \n",
    "    print(f\"MLFlow Run ID: {run.info.run_id}\")\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    \n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"trip_duration_minutes\",\n",
    "        maxIter=10,\n",
    "        regParam=0.01\n",
    "    )\n",
    "    \n",
    "    lr_model = lr.fit(train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    predictions_lr = lr_model.transform(test)\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName: \"rmse\"})\n",
    "    mae_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName: \"mae\"})\n",
    "    r2_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName: \"r2\"})\n",
    "    \n",
    "    # Log additional metrics\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    mlflow.log_metric(\"rmse\", rmse_lr)  \n",
    "    mlflow.log_metric(\"mae\", mae_lr)    \n",
    "    mlflow.log_metric(\"r2\", r2_lr)    \n",
    "    mlflow.log_param(\"model_type\", \"Linear Regression\")\n",
    "    mlflow.log_param(\"distributed_training\", \"False\")\n",
    "    \n",
    "    print(f\"\\nTraining time: {training_time:.2f} seconds\")\n",
    "    print(f\"RMSE: {rmse_lr:.2f} minutes\")\n",
    "    print(f\"MAE: {mae_lr:.2f} minutes\")\n",
    "    print(f\"R²: {r2_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36fb8d2a-54bc-43cd-b1c7-b4ebc02be1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n============================================================\nMODEL 2: RANDOM FOREST (DISTRIBUTED TRAINING)\n============================================================\nMLFlow Run ID: 0af8d89acebb4a67958621b6fccdf8e8\n\nTraining Random Forest with distributed data parallelism...\n- Each worker trains subset of trees independently\n- Trees aggregated at driver to form ensemble\n\nTraining time: 809.72 seconds\nRMSE: 5.17 minutes\nMAE: 2.55 minutes\nR²: 0.8571\n\nTop 5 Feature Importances:\n  fare_amount: 0.5900\n  trip_distance: 0.2691\n  PULocationID_idx: 0.0806\n  hour_of_day: 0.0281\n  DOLocationID_idx: 0.0259\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Model 2 - Random Forest\n",
    "# DS FEATURE: DISTRIBUTED ML TRAINING (Data Parallelism)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 2: RANDOM FOREST (DISTRIBUTED TRAINING)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with mlflow.start_run(run_name=\"02_random_forest_v1\") as run:\n",
    "    \n",
    "    print(f\"MLFlow Run ID: {run.info.run_id}\")\n",
    "    print(\"\\nTraining Random Forest with distributed data parallelism...\")\n",
    "    print(\"- Each worker trains subset of trees independently\")\n",
    "    print(\"- Trees aggregated at driver to form ensemble\")\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    \n",
    "    rf = RandomForestRegressor(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"trip_duration_minutes\",\n",
    "        numTrees=50,\n",
    "        maxDepth=7,\n",
    "        minInstancesPerNode=1,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    rf_model = rf.fit(train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    predictions_rf = rf_model.transform(test)\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse_rf = evaluator.evaluate(predictions_rf, {evaluator.metricName: \"rmse\"})\n",
    "    mae_rf = evaluator.evaluate(predictions_rf, {evaluator.metricName: \"mae\"})\n",
    "    r2_rf = evaluator.evaluate(predictions_rf, {evaluator.metricName: \"r2\"})\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    mlflow.log_metric(\"rmse\", rmse_rf)  \n",
    "    mlflow.log_metric(\"mae\", mae_rf)    \n",
    "    mlflow.log_metric(\"r2\", r2_rf)      \n",
    "    mlflow.log_param(\"model_type\", \"Random Forest\")\n",
    "    mlflow.log_param(\"distributed_training\", \"True\")\n",
    "    \n",
    "    # Log feature importance\n",
    "    feature_importance = rf_model.featureImportances.toArray()\n",
    "    for idx, importance in enumerate(feature_importance):\n",
    "        mlflow.log_metric(f\"feature_{idx}_importance\", float(importance))\n",
    "    \n",
    "    print(f\"\\nTraining time: {training_time:.2f} seconds\")\n",
    "    print(f\"RMSE: {rmse_rf:.2f} minutes\")\n",
    "    print(f\"MAE: {mae_rf:.2f} minutes\")\n",
    "    print(f\"R²: {r2_rf:.4f}\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    print(\"\\nTop 5 Feature Importances:\")\n",
    "    feature_names = [\"trip_distance\", \"passenger_count\", \"fare_amount\", \n",
    "                     \"hour_of_day\", \"day_of_week\", \"is_weekend\", \"PULocationID_idx\", \"DOLocationID_idx\"]\n",
    "    importance_pairs = list(zip(feature_names, feature_importance))\n",
    "    importance_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "    for name, imp in importance_pairs[:5]:\n",
    "        print(f\"  {name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "021223e0-c53a-4be7-9f13-6d246e71a01b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n============================================================\nMODEL 3: GRADIENT BOOSTED TREES\n============================================================\nMLFlow Run ID: 9254956582fb4d19bec2029d0e6f6fb4\n\nTraining time: 3061.72 seconds\nRMSE: 4.79 minutes\nMAE: 2.22 minutes\nR²: 0.8776\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Model 3 - Gradient Boosted Trees\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 3: GRADIENT BOOSTED TREES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with mlflow.start_run(run_name=\"03_gbt_v1\") as run:\n",
    "    \n",
    "    print(f\"MLFlow Run ID: {run.info.run_id}\")\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gbt = GBTRegressor(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"trip_duration_minutes\",\n",
    "        maxIter=20,\n",
    "        maxDepth=5,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    gbt_model = gbt.fit(train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    test_sample = test.sample(fraction=0.3, seed=42)\n",
    "    predictions_gbt = gbt_model.transform(test_sample)\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse_gbt = evaluator.evaluate(predictions_gbt, {evaluator.metricName: \"rmse\"})\n",
    "    mae_gbt = evaluator.evaluate(predictions_gbt, {evaluator.metricName: \"mae\"})\n",
    "    r2_gbt = evaluator.evaluate(predictions_gbt, {evaluator.metricName: \"r2\"})\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    mlflow.log_metric(\"rmse\", rmse_gbt)  \n",
    "    mlflow.log_metric(\"mae\", mae_gbt)    \n",
    "    mlflow.log_metric(\"r2\", r2_gbt)     \n",
    "    mlflow.log_param(\"model_type\", \"Gradient Boosted Trees\")\n",
    "    \n",
    "    print(f\"\\nTraining time: {training_time:.2f} seconds\")\n",
    "    print(f\"RMSE: {rmse_gbt:.2f} minutes\")\n",
    "    print(f\"MAE: {mae_gbt:.2f} minutes\")\n",
    "    print(f\"R²: {r2_gbt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd3b73b-3a61-403e-bd55-0541f7578d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n======================================================================\nMODEL COMPARISON SUMMARY\n======================================================================\n\nModel                     RMSE (min)      MAE (min)       R²        \n----------------------------------------------------------------------\nLinear Regression         7.30            4.22            0.7151    \nRandom Forest             5.17            2.55            0.8571    \nGradient Boosted Trees    4.79            2.22            0.8776    \n\n======================================================================\nBEST MODEL: Gradient Boosted Trees\nRMSE: 4.79 minutes\n======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Compare All Models\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = [\n",
    "    (\"Linear Regression\", rmse_lr, mae_lr, r2_lr),\n",
    "    (\"Random Forest\", rmse_rf, mae_rf, r2_rf),\n",
    "    (\"Gradient Boosted Trees\", rmse_gbt, mae_gbt, r2_gbt)\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Model':<25} {'RMSE (min)':<15} {'MAE (min)':<15} {'R²':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for model, rmse, mae, r2 in comparison_data:\n",
    "    print(f\"{model:<25} {rmse:<15.2f} {mae:<15.2f} {r2:<10.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = min(range(len(comparison_data)), key=lambda i: comparison_data[i][1])\n",
    "best_model_name = comparison_data[best_model_idx][0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"RMSE: {comparison_data[best_model_idx][1]:.2f} minutes\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983636d3-13b5-4260-96bd-f1b0fcfa124e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n======================================================================\nSTORING BEST MODEL METADATA\n======================================================================\n\nBest Model: gradient_boosted_trees\n  RMSE: 4.79 minutes\n  MAE: 2.22 minutes\n  R²: 0.8776\n\nModel metrics saved to table: model_comparison_metrics\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Store Best Model Metadata for Registry\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STORING BEST MODEL METADATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find best model by lowest RMSE\n",
    "best_metrics = {\n",
    "    \"linear_regression\": {\"rmse\": rmse_lr, \"mae\": mae_lr, \"r2\": r2_lr},\n",
    "    \"random_forest\": {\"rmse\": rmse_rf, \"mae\": mae_rf, \"r2\": r2_rf},\n",
    "    \"gradient_boosted_trees\": {\"rmse\": rmse_gbt, \"mae\": mae_gbt, \"r2\": r2_gbt}\n",
    "}\n",
    "\n",
    "# Find model with lowest RMSE\n",
    "best_model_name = min(best_metrics.keys(), key=lambda k: best_metrics[k][\"rmse\"])\n",
    "best_model_metrics = best_metrics[best_model_name]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"  RMSE: {best_model_metrics['rmse']:.2f} minutes\")\n",
    "print(f\"  MAE: {best_model_metrics['mae']:.2f} minutes\")\n",
    "print(f\"  R²: {best_model_metrics['r2']:.4f}\")\n",
    "\n",
    "# Save to Delta table for easy retrieval\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"model_name\", StringType(), False),\n",
    "    StructField(\"rmse\", DoubleType(), False),\n",
    "    StructField(\"mae\", DoubleType(), False),\n",
    "    StructField(\"r2\", DoubleType(), False),\n",
    "    StructField(\"timestamp\", StringType(), False)\n",
    "])\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "model_comparison_data = [\n",
    "    (\"linear_regression\", rmse_lr, mae_lr, r2_lr, datetime.now().isoformat()),\n",
    "    (\"random_forest\", rmse_rf, mae_rf, r2_rf, datetime.now().isoformat()),\n",
    "    (\"gradient_boosted_trees\", rmse_gbt, mae_gbt, r2_gbt, datetime.now().isoformat())\n",
    "]\n",
    "\n",
    "model_comparison_df = spark.createDataFrame(model_comparison_data, schema=schema)\n",
    "\n",
    "# Save to Delta table\n",
    "model_comparison_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"model_comparison_metrics\")\n",
    "\n",
    "print(\"\\nModel metrics saved to table: model_comparison_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2caa8006-0315-4a03-8f41-fe2f7cec728a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nSaving best model (gradient_boosted_trees)...\nBest model saved to: /mnt/taxi-data/models/best_gradient_boosted_trees\n   Model Type: gradient_boosted_trees\n   RMSE: 4.79 minutes\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Save Best Model (Dynamic Selection)\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\nSaving best model ({best_model_name})...\")\n",
    "\n",
    "# Save the actual best model based on metrics\n",
    "if best_model_name == \"linear_regression\":\n",
    "    best_model_object = lr_model\n",
    "elif best_model_name == \"random_forest\":\n",
    "    best_model_object = rf_model\n",
    "else:  # gradient_boosted_trees\n",
    "    best_model_object = gbt_model\n",
    "\n",
    "# Save to DBFS with dynamic name\n",
    "model_save_path = f\"/mnt/taxi-data/models/best_{best_model_name}\"\n",
    "best_model_object.write().overwrite().save(model_save_path)\n",
    "\n",
    "print(f\"Best model saved to: {model_save_path}\")\n",
    "print(f\"   Model Type: {best_model_name}\")\n",
    "print(f\"   RMSE: {best_model_metrics['rmse']:.2f} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Baseline_Models_MLFlow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}